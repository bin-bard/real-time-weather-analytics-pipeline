{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9984e697-6817-4d1b-89f3-a75bc9151e51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Kh·ªüi t·∫°o SparkSession v·ªõi t·∫•t c·∫£ c·∫•u h√¨nh c·∫ßn thi·∫øt\n",
    "builder = SparkSession.builder \\\n",
    "    .appName(\"WeatherPrediction\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.executor.memory\", \"12g\")\n",
    "\n",
    "# √Åp d·ª•ng c·∫•u h√¨nh Delta v√† kh·ªüi t·∫°o SparkSession\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1c32942-e67d-4ca8-a966-ae89aa5146b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71b94c7c-47c7-402a-bac2-502c3d01b095",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----+-----------+---------+----+---------+----+-----+--------+-------------+--------+--------------------+----+------------------------+----------------------+-----------------+----------------------+-----------------+------------------+---------------------+--------------------------+---------------------+--------------------+--------------------+-----------------+\n| time|month|year|temperature|feelslike|wind|direction|gust|cloud|humidity|precipitation|pressure|             weather|Rain|temperature_after_3_hour|feelslike_after_3_hour|wind_after_3_hour|direction_after_3_hour|gust_after_3_hour|cloud_after_3_hour|humidity_after_3_hour|precipitation_after_3_hour|pressure_after_3_hour|weather_after_3_hour|               label|rain_after_3_hour|\n+-----+-----+----+-----------+---------+----+---------+----+-----+--------+-------------+--------+--------------------+----+------------------------+----------------------+-----------------+----------------------+-----------------+------------------+---------------------+--------------------------+---------------------+--------------------+--------------------+-----------------+\n|00:00|    1|2017|       24.0|     28.0| 8.0|      ENE|12.0|  4.0|    86.0|          0.0|  1012.0|               Clear|   0|                    23.0|                  27.0|              8.0|                    NE|             10.0|               4.0|                 88.0|                       0.0|               1011.0|               Clear|               Clear|                0|\n|03:00|    1|2017|       23.0|     27.0| 8.0|       NE|10.0|  4.0|    88.0|          0.0|  1011.0|               Clear|   0|                    23.0|                  26.0|              8.0|                   NNE|             11.0|               7.0|                 85.0|                       0.0|               1012.0|               Sunny|               Sunny|                0|\n|06:00|    1|2017|       23.0|     26.0| 8.0|      NNE|11.0|  7.0|    85.0|          0.0|  1012.0|               Sunny|   0|                    28.0|                  33.0|             11.0|                   NNE|             13.0|               6.0|                 64.0|                       0.0|               1012.0|               Sunny|               Sunny|                0|\n|09:00|    1|2017|       28.0|     33.0|11.0|      NNE|13.0|  6.0|    64.0|          0.0|  1012.0|               Sunny|   0|                    31.0|                  35.0|             10.0|                   ENE|             12.0|              62.0|                 53.0|                       0.0|               1010.0|       Partly cloudy|       Partly cloudy|                0|\n|12:00|    1|2017|       31.0|     35.0|10.0|      ENE|12.0| 62.0|    53.0|          0.0|  1010.0|       Partly cloudy|   0|                    31.0|                  36.0|              1.0|                   NNE|              1.0|              79.0|                 57.0|                       0.0|               1009.0|              Cloudy|              Cloudy|                0|\n|15:00|    1|2017|       31.0|     36.0| 1.0|      NNE| 1.0| 79.0|    57.0|          0.0|  1009.0|              Cloudy|   0|                    26.0|                  29.0|              5.0|                   ESE|             10.0|              40.0|                 77.0|                       0.0|               1010.0|       Partly cloudy|       Partly cloudy|                0|\n|18:00|    1|2017|       26.0|     29.0| 5.0|      ESE|10.0| 40.0|    77.0|          0.0|  1010.0|       Partly cloudy|   0|                    25.0|                  28.0|              8.0|                    NE|             15.0|              29.0|                 79.0|                       0.2|               1011.0|Patchy rain possible|Patchy rain possible|                0|\n|21:00|    1|2017|       25.0|     28.0| 8.0|       NE|15.0| 29.0|    79.0|          0.2|  1011.0|Patchy rain possible|   0|                    24.0|                  26.0|             10.0|                   NNE|             17.0|              12.0|                 84.0|                       0.0|               1011.0|               Clear|               Clear|                0|\n|00:00|    1|2017|       24.0|     26.0|10.0|      NNE|17.0| 12.0|    84.0|          0.0|  1011.0|               Clear|   0|                    23.0|                  26.0|              8.0|                    NE|             14.0|              17.0|                 85.0|                       0.0|               1010.0|               Clear|               Clear|                0|\n|03:00|    1|2017|       23.0|     26.0| 8.0|       NE|14.0| 17.0|    85.0|          0.0|  1010.0|               Clear|   0|                    24.0|                  26.0|             10.0|                    NE|             14.0|              16.0|                 80.0|                       0.0|               1011.0|               Clear|               Clear|                0|\n|06:00|    1|2017|       24.0|     26.0|10.0|       NE|14.0| 16.0|    80.0|          0.0|  1011.0|               Clear|   0|                    29.0|                  32.0|             12.0|                    NE|             14.0|               9.0|                 62.0|                       0.0|               1012.0|               Sunny|               Sunny|                0|\n|09:00|    1|2017|       29.0|     32.0|12.0|       NE|14.0|  9.0|    62.0|          0.0|  1012.0|               Sunny|   0|                    32.0|                  36.0|             12.0|                     E|             14.0|              55.0|                 53.0|                       0.0|               1010.0|       Partly cloudy|       Partly cloudy|                0|\n|12:00|    1|2017|       32.0|     36.0|12.0|        E|14.0| 55.0|    53.0|          0.0|  1010.0|       Partly cloudy|   0|                    31.0|                  36.0|              9.0|                     E|             13.0|              19.0|                 59.0|                       1.6|               1009.0|Patchy rain possible|Patchy rain possible|                0|\n|15:00|    1|2017|       31.0|     36.0| 9.0|        E|13.0| 19.0|    59.0|          1.6|  1009.0|Patchy rain possible|   0|                    26.0|                  30.0|              6.0|                   ESE|             12.0|              34.0|                 76.0|                       0.0|               1011.0|       Partly cloudy|       Partly cloudy|                0|\n|18:00|    1|2017|       26.0|     30.0| 6.0|      ESE|12.0| 34.0|    76.0|          0.0|  1011.0|       Partly cloudy|   0|                    25.0|                  28.0|              9.0|                   ENE|             17.0|              21.0|                 77.0|                       0.0|               1012.0|               Clear|               Clear|                0|\n|21:00|    1|2017|       25.0|     28.0| 9.0|      ENE|17.0| 21.0|    77.0|          0.0|  1012.0|               Clear|   0|                    24.0|                  27.0|              9.0|                    NE|             15.0|              32.0|                 84.0|                       0.0|               1011.0|       Partly cloudy|       Partly cloudy|                0|\n|00:00|    1|2017|       24.0|     27.0| 9.0|       NE|15.0| 32.0|    84.0|          0.0|  1011.0|       Partly cloudy|   0|                    23.0|                  26.0|              8.0|                    NE|             14.0|              38.0|                 85.0|                       0.0|               1010.0|       Partly cloudy|       Partly cloudy|                0|\n|03:00|    1|2017|       23.0|     26.0| 8.0|       NE|14.0| 38.0|    85.0|          0.0|  1010.0|       Partly cloudy|   0|                    23.0|                  26.0|              8.0|                    NE|             11.0|              20.0|                 83.0|                       0.0|               1011.0|               Sunny|               Sunny|                0|\n|06:00|    1|2017|       23.0|     26.0| 8.0|       NE|11.0| 20.0|    83.0|          0.0|  1011.0|               Sunny|   0|                    28.0|                  31.0|             10.0|                    NE|             12.0|              12.0|                 64.0|                       0.0|               1011.0|               Sunny|               Sunny|                0|\n|09:00|    1|2017|       28.0|     31.0|10.0|       NE|12.0| 12.0|    64.0|          0.0|  1011.0|               Sunny|   0|                    32.0|                  36.0|              9.0|                     E|             10.0|              18.0|                 49.0|                       0.0|               1009.0|               Sunny|               Sunny|                0|\n+-----+-----+----+-----------+---------+----+---------+----+-----+--------+-------------+--------+--------------------+----+------------------------+----------------------+-----------------+----------------------+-----------------+------------------+---------------------+--------------------------+---------------------+--------------------+--------------------+-----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# ƒê∆∞·ªùng d·∫´n ƒë·∫øn HDFS tr√™n localhost:9000\n",
    "delta_table_path = \"dbfs:/minhhieu/delta/gold/weather_features\"\n",
    "\n",
    "\n",
    "# ƒê·ªçc l·∫°i d·ªØ li·ªáu t·ª´ Delta Table\n",
    "df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "num_rows = df.count()\n",
    "\n",
    "df = df.limit(num_rows - 1)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef66081f-dd33-4a76-ba79-2d6a9a326524",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S·ªë l∆∞·ª£ng c·ªôt: 26\nS·ªë l∆∞·ª£ng d√≤ng: 8510\n"
     ]
    }
   ],
   "source": [
    "# ƒê·∫øm s·ªë l∆∞·ª£ng c·ªôt\n",
    "num_columns = len(df.columns)\n",
    "print(f\"S·ªë l∆∞·ª£ng c·ªôt: {num_columns}\")\n",
    "\n",
    "# ƒê·∫øm s·ªë l∆∞·ª£ng d√≤ng\n",
    "num_rows = df.count()\n",
    "print(f\"S·ªë l∆∞·ª£ng d√≤ng: {num_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac234b5f-d2ab-47a3-ae46-04211ed4fab1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping Direction: {'ENE': 8, 'NE': 10, 'NNE': 9, 'ESE': 3, 'E': 5, 'SE': 0, 'SSE': 4, 'NNW': 14, 'WSW': 1, 'S': 11, 'WNW': 12, 'NW': 15, 'W': 7, 'SW': 2, 'SSW': 6, 'N': 13}\nMapping Weather: {'Clear': 1, 'Sunny': 2, 'Partly cloudy': 0, 'Cloudy': 5, 'Patchy rain possible': 3, 'Light rain shower': 6, 'Overcast': 7, 'Moderate or heavy rain shower': 4, 'Patchy light drizzle': 12, 'Torrential rain shower': 9, 'Light drizzle': 14, 'Patchy light rain': 10, 'Thundery outbreaks possible': 8, 'Light rain': 13, 'Patchy light rain with thunder': 11, 'Moderate rain': 17, 'Moderate rain at times': 16, 'Mist': 15, 'Heavy rain at times': 19, 'Heavy rain': 18}\nMapping Direction After 3 Hours: {'NE': 10, 'NNE': 9, 'ENE': 8, 'ESE': 3, 'E': 5, 'SE': 0, 'SSE': 4, 'NNW': 14, 'WSW': 1, 'S': 11, 'WNW': 12, 'NW': 15, 'W': 7, 'SW': 2, 'SSW': 6, 'N': 13}\nMapping Weather After 3 Hours: {'Clear': 1, 'Sunny': 2, 'Partly cloudy': 0, 'Cloudy': 5, 'Patchy rain possible': 3, 'Light rain shower': 6, 'Overcast': 7, 'Moderate or heavy rain shower': 4, 'Patchy light drizzle': 12, 'Torrential rain shower': 9, 'Light drizzle': 14, 'Patchy light rain': 10, 'Thundery outbreaks possible': 8, 'Light rain': 13, 'Patchy light rain with thunder': 11, 'Moderate rain': 17, 'Moderate rain at times': 16, 'Mist': 15, 'Heavy rain at times': 19, 'Heavy rain': 18}\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# T·∫°o b·ªô chuy·ªÉn ƒë·ªïi cho c√°c c·ªôt\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=\"direction\", outputCol=\"direction_index\"),\n",
    "    StringIndexer(inputCol=\"weather\", outputCol=\"weather_index\"),\n",
    "    StringIndexer(inputCol=\"direction_after_3_hour\", outputCol=\"direction_after_index\"),\n",
    "    StringIndexer(inputCol=\"weather_after_3_hour\", outputCol=\"weather_after_index\"),\n",
    "]\n",
    "\n",
    "# √Åp d·ª•ng pipeline ƒë·ªÉ chuy·ªÉn ƒë·ªïi t·∫•t c·∫£ c√°c c·ªôt c√πng l√∫c\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "df = pipeline.fit(df).transform(df)\n",
    "\n",
    "# Tr√≠ch xu·∫•t √°nh x·∫° th√†nh dictionary\n",
    "direction_mapping = df.select(\"direction\", \"direction_index\").distinct().collect()\n",
    "weather_mapping = df.select(\"weather\", \"weather_index\").distinct().collect()\n",
    "direction_after_mapping = df.select(\"direction_after_3_hour\", \"direction_after_index\").distinct().collect()\n",
    "weather_after_mapping = df.select(\"weather_after_3_hour\", \"weather_after_index\").distinct().collect()\n",
    "\n",
    "# L∆∞u v√†o dictionary\n",
    "direction_dict = {row[\"direction\"]: int(row[\"direction_index\"]) for row in direction_mapping}\n",
    "weather_dict = {row[\"weather\"]: int(row[\"weather_index\"]) for row in weather_mapping}\n",
    "direction_after_dict = {row[\"direction_after_3_hour\"]: int(row[\"direction_after_index\"]) for row in direction_after_mapping}\n",
    "weather_after_dict = {row[\"weather_after_3_hour\"]: int(row[\"weather_after_index\"]) for row in weather_after_mapping}\n",
    "\n",
    "# In k·∫øt qu·∫£\n",
    "print(\"Mapping Direction:\", direction_dict)\n",
    "print(\"Mapping Weather:\", weather_dict)\n",
    "print(\"Mapping Direction After 3 Hours:\", direction_after_dict)\n",
    "print(\"Mapping Weather After 3 Hours:\", weather_after_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd0c6bf5-1106-4cb1-b2ae-0d54da34d290",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Thay th·∫ø c·ªôt chu·ªói b·∫±ng c·ªôt ƒë√£ m√£ h√≥a\n",
    "df = df \\\n",
    "    .drop(\"direction\", \"weather\", \"direction_after_3_hour\", \"weather_after_3_hour\") \\\n",
    "    .withColumnRenamed(\"direction_index\", \"direction\") \\\n",
    "    .withColumnRenamed(\"weather_index\", \"weather\") \\\n",
    "    .withColumnRenamed(\"direction_after_index\", \"direction_after_3_hour\") \\\n",
    "    .withColumnRenamed(\"weather_after_index\", \"weather_after_3_hour\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "412008ce-a2b1-44ea-a316-b9781e5d4eb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "# S·ª≠a c·ªôt 'time', lo·∫°i b·ªè ':00'\n",
    "df = df.withColumn(\"time\", regexp_replace(\"time\", \":00\", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99d0746a-6852-4a09-b581-4a9ce9840917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def cast_columns_to_float(df: DataFrame, columns: list) -> DataFrame:\n",
    "    for c in columns:\n",
    "        df = df.withColumn(c, col(c).cast(\"float\"))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc4059eb-ff25-41f1-b280-0b1d21e4ca66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sin, cos, col\n",
    "import math\n",
    "\n",
    "# Chuy·ªÉn ƒë·ªïi c·ªôt 'time' (gi·ªù trong ng√†y) th√†nh sin/cos\n",
    "df = df.withColumn(\"time_sin\", sin(2 * math.pi * col(\"time\") / 24))\n",
    "df = df.withColumn(\"time_cos\", cos(2 * math.pi * col(\"time\") / 24))\n",
    "\n",
    "# Chuy·ªÉn ƒë·ªïi c·ªôt 'month' (th√°ng trong nƒÉm) th√†nh sin/cos\n",
    "df = df.withColumn(\"month_sin\", sin(2 * math.pi * col(\"month\") / 12))\n",
    "df = df.withColumn(\"month_cos\", cos(2 * math.pi * col(\"month\") / 12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7833ce2f-344d-40f7-9188-d17d18f84222",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_cols = [\n",
    "    'time', 'month', 'temperature', 'feelslike', 'wind',\n",
    "    'direction', 'gust', 'cloud', 'humidity', 'precipitation',\n",
    "    'pressure',\n",
    "    'time_sin', 'time_cos',  # Bi·ªÉu di·ªÖn th·ªùi gian trong ng√†y\n",
    "    'month_sin', 'month_cos'  # Bi·ªÉu di·ªÖn th√°ng trong nƒÉm\n",
    "]\n",
    "\n",
    "output_cols = [\n",
    "    'temperature_after_3_hour',\n",
    "    'feelslike_after_3_hour',\n",
    "    'wind_after_3_hour',\n",
    "    'direction_after_3_hour',\n",
    "    'gust_after_3_hour',\n",
    "    'cloud_after_3_hour',\n",
    "    'humidity_after_3_hour',\n",
    "    'precipitation_after_3_hour',\n",
    "    'pressure_after_3_hour'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d28b6688-678f-4651-80ed-5767143002ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = cast_columns_to_float(df, input_cols + output_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13ff4974-4441-4745-af36-1a210d7b3581",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- time: float (nullable = true)\n |-- month: float (nullable = true)\n |-- year: string (nullable = true)\n |-- temperature: float (nullable = true)\n |-- feelslike: float (nullable = true)\n |-- wind: float (nullable = true)\n |-- gust: float (nullable = true)\n |-- cloud: float (nullable = true)\n |-- humidity: float (nullable = true)\n |-- precipitation: float (nullable = true)\n |-- pressure: float (nullable = true)\n |-- Rain: integer (nullable = true)\n |-- temperature_after_3_hour: float (nullable = true)\n |-- feelslike_after_3_hour: float (nullable = true)\n |-- wind_after_3_hour: float (nullable = true)\n |-- gust_after_3_hour: float (nullable = true)\n |-- cloud_after_3_hour: float (nullable = true)\n |-- humidity_after_3_hour: float (nullable = true)\n |-- precipitation_after_3_hour: float (nullable = true)\n |-- pressure_after_3_hour: float (nullable = true)\n |-- label: string (nullable = true)\n |-- rain_after_3_hour: integer (nullable = true)\n |-- direction: float (nullable = false)\n |-- weather: double (nullable = false)\n |-- direction_after_3_hour: float (nullable = false)\n |-- weather_after_3_hour: double (nullable = false)\n |-- time_sin: float (nullable = true)\n |-- time_cos: float (nullable = true)\n |-- month_sin: float (nullable = true)\n |-- month_cos: float (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92c885bf-4b8f-4279-b9d0-9af9d7922d81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=input_cols, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1188f08f-a900-4021-b6b3-b3847a4c8ae0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh cho: temperature_after_3_hour\n‚úÖ RMSE cho temperature_after_3_hour: 1.877\nüéØ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh cho: feelslike_after_3_hour\n‚úÖ RMSE cho feelslike_after_3_hour: 1.613\nüéØ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh cho: wind_after_3_hour\n‚úÖ RMSE cho wind_after_3_hour: 2.428\nüéØ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh cho: direction_after_3_hour\n‚úÖ RMSE cho direction_after_3_hour: 3.391\nüéØ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh cho: gust_after_3_hour\n‚úÖ RMSE cho gust_after_3_hour: 4.306\nüéØ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh cho: cloud_after_3_hour\n‚úÖ RMSE cho cloud_after_3_hour: 22.324\nüéØ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh cho: humidity_after_3_hour\n‚úÖ RMSE cho humidity_after_3_hour: 4.184\nüéØ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh cho: precipitation_after_3_hour\n‚úÖ RMSE cho precipitation_after_3_hour: 1.972\nüéØ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh cho: pressure_after_3_hour\n‚úÖ RMSE cho pressure_after_3_hour: 0.904\n"
     ]
    }
   ],
   "source": [
    "# Th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, col\n",
    "\n",
    "# L·∫∑p qua t·ª´ng c·ªôt ƒë·∫ßu ra (output c·∫ßn d·ª± ƒëo√°n) ‚Äì ngo·∫°i tr·ª´ 'weather_after_3_hour' v√¨ ƒë√¢y l√† ph√¢n lo·∫°i\n",
    "for target in output_cols:  # B·ªè weather_after_3_hour (classification)\n",
    "    # Lo·∫°i b·ªè c√°c d√≤ng ch·ª©a gi√° tr·ªã null trong c·ªôt ƒë·∫∑c tr∆∞ng (input) v√† nh√£n m·ª•c ti√™u (target)\n",
    "    current_df = df.dropna(subset=input_cols + [target])\n",
    "\n",
    "    # N·∫øu sau khi l·ªçc kh√¥ng c√≤n d√≤ng n√†o ‚Üí b·ªè qua m√¥ h√¨nh n√†y\n",
    "    if current_df.count() == 0:\n",
    "        print(f\"‚ö†Ô∏è B·ªè qua {target} v√¨ kh√¥ng c√≤n d√≤ng sau khi dropna.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"üéØ ƒêang hu·∫•n luy·ªán m√¥ h√¨nh cho: {target}\")\n",
    "\n",
    "    # T·∫°o c·ªôt s·ªë th·ª© t·ª± d√≤ng ƒë·ªÉ chia d·ªØ li·ªáu theo th·ªùi gian (gi·∫£ l·∫≠p th·ªùi gian b·∫±ng th·ª© t·ª±)\n",
    "    window = Window.orderBy(monotonically_increasing_id())\n",
    "    indexed_df = current_df.withColumn(\"row_num\", row_number().over(window))\n",
    "\n",
    "    # Chia t·∫≠p train/test theo th·ª© t·ª± d√≤ng (80% hu·∫•n luy·ªán, 20% ki·ªÉm th·ª≠)\n",
    "    total_rows = indexed_df.count()\n",
    "    split_point = int(total_rows * 0.8)\n",
    "\n",
    "    train_data = indexed_df.filter(col(\"row_num\") <= split_point).drop(\"row_num\")\n",
    "    test_data = indexed_df.filter(col(\"row_num\") > split_point).drop(\"row_num\")\n",
    "\n",
    "    # Kh·ªüi t·∫°o v√† hu·∫•n luy·ªán m√¥ h√¨nh Random Forest h·ªìi quy\n",
    "    model = RandomForestRegressor(\n",
    "        featuresCol=\"features\",  # C·ªôt ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o\n",
    "        labelCol=target,         # C·ªôt ƒë·∫ßu ra c·∫ßn d·ª± ƒëo√°n\n",
    "        numTrees=100             # S·ªë c√¢y trong r·ª´ng\n",
    "    )\n",
    "    model_fitted = model.fit(train_data)\n",
    "\n",
    "    # D·ª± ƒëo√°n tr√™n t·∫≠p ki·ªÉm th·ª≠ v√† ƒë√°nh gi√° b·∫±ng ch·ªâ s·ªë RMSE\n",
    "    predictions = model_fitted.transform(test_data)\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=target,\n",
    "        predictionCol=\"prediction\",\n",
    "        metricName=\"rmse\"       # Root Mean Squared Error\n",
    "    )\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "    print(f\"‚úÖ RMSE cho {target}: {rmse:.3f}\")\n",
    "\n",
    "    # L∆∞u m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán v√†o th∆∞ m·ª•c tr√™n DBFS (Databricks File System)\n",
    "    model_fitted.write().overwrite().save(f\"dbfs:/minhhieu/delta/models/{target}_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b1e233f-54e2-4f92-9cc5-878c021ec0c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Accuracy for weather_after_3_hour: 0.583\n‚úÖ F1-score for weather_after_3_hour: 0.535\n"
     ]
    }
   ],
   "source": [
    "# Th∆∞ vi·ªán c·∫ßn thi·∫øt t·ª´ PySpark ML\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm th·ª≠ (80% train, 20% test)\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Kh·ªüi t·∫°o m√¥ h√¨nh Random Forest Classifier\n",
    "clf = RandomForestClassifier(\n",
    "    featuresCol=\"features\",                    # C·ªôt ch·ª©a vector ƒë·∫∑c tr∆∞ng\n",
    "    labelCol=\"weather_after_3_hour\",           # C·ªôt nh√£n ph√¢n lo·∫°i ƒë·∫ßu ra\n",
    "    numTrees=200,                              # S·ªë c√¢y trong r·ª´ng\n",
    "    maxDepth=10                                # ƒê·ªô s√¢u t·ªëi ƒëa c·ªßa m·ªói c√¢y\n",
    ")\n",
    "\n",
    "# Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi t·∫≠p train\n",
    "model = clf.fit(train_data)\n",
    "\n",
    "# D·ª± ƒëo√°n tr√™n t·∫≠p test\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Kh·ªüi t·∫°o b·ªô ƒë√°nh gi√° Accuracy v√† F1-score\n",
    "acc_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"weather_after_3_hour\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"                     # T√≠nh ƒë·ªô ch√≠nh x√°c\n",
    ")\n",
    "\n",
    "f1_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"weather_after_3_hour\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"                           # T√≠nh ch·ªâ s·ªë F1 (harmonic mean gi·ªØa precision & recall)\n",
    ")\n",
    "\n",
    "# T√≠nh to√°n ƒë·ªô ch√≠nh x√°c v√† F1-score tr√™n t·∫≠p ki·ªÉm th·ª≠\n",
    "accuracy = acc_evaluator.evaluate(predictions)\n",
    "f1_score = f1_evaluator.evaluate(predictions)\n",
    "\n",
    "# In k·∫øt qu·∫£ ra m√†n h√¨nh\n",
    "print(f\"‚úÖ Accuracy for weather_after_3_hour: {accuracy:.3f}\")\n",
    "print(f\"‚úÖ F1-score for weather_after_3_hour: {f1_score:.3f}\")\n",
    "\n",
    "# L∆∞u m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán v√†o h·ªá th·ªëng t·ªáp (DBFS ‚Äì Databricks File System)\n",
    "model.write().overwrite().save(\"dbfs:/minhhieu/delta/models/weather_classifier_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16555183-2551-46f9-b735-390e08b13375",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n|weather_after_3_hour|\n+--------------------+\n|                 1.0|\n|                 2.0|\n|                 0.0|\n|                 5.0|\n|                 3.0|\n|                 6.0|\n|                 7.0|\n|                 4.0|\n|                12.0|\n|                 9.0|\n|                14.0|\n|                10.0|\n|                 8.0|\n|                13.0|\n|                11.0|\n|                17.0|\n|                16.0|\n|                15.0|\n|                19.0|\n|                18.0|\n+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select(\"weather_after_3_hour\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91499a03-8ac8-46d6-939b-c163d905e38b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# G√°n nh√£n: c√°c lo·∫°i th·ªùi ti·∫øt li√™n quan ƒë·∫øn m∆∞a ‚Üí 1, c√≤n l·∫°i ‚Üí 0\n",
    "rain_labels = [3, 4, 6, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19]  # c√°c gi√° tr·ªã mapping t∆∞∆°ng ·ª©ng v·ªõi m∆∞a\n",
    "\n",
    "df = df.withColumn(\"label_after_3_hour\", when(col(\"weather_after_3_hour\").isin(rain_labels), 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12d0f1b0-dc04-4797-af97-27e71b8cb037",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Accuracy for weather_after_3_hour: 0.876\n‚úÖ F1-score for weather_after_3_hour: 0.870\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Train-test split\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# RandomForestClassifier\n",
    "clf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label_after_3_hour\", numTrees=200, maxDepth=10)\n",
    "\n",
    "model = clf.fit(train_data)\n",
    "\n",
    "# D·ª± ƒëo√°n\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# ƒê√°nh gi√°\n",
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"label_after_3_hour\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"label_after_3_hour\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "accuracy = acc_evaluator.evaluate(predictions)\n",
    "f1_score = f1_evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"‚úÖ Accuracy for weather_after_3_hour: {accuracy:.3f}\")\n",
    "print(f\"‚úÖ F1-score for weather_after_3_hour: {f1_score:.3f}\")\n",
    "\n",
    "model.write().overwrite().save(\"dbfs:/minhhieu/delta/models/weather_classifier_model_2\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "train",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}