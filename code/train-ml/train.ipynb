{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9984e697-6817-4d1b-89f3-a75bc9151e51",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from delta import configure_spark_with_delta_pip\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Khởi tạo SparkSession với tất cả cấu hình cần thiết\n",
    "builder = SparkSession.builder \\\n",
    "    .appName(\"WeatherPrediction\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.driver.memory\", \"12g\") \\\n",
    "    .config(\"spark.executor.memory\", \"12g\")\n",
    "\n",
    "# Áp dụng cấu hình Delta và khởi tạo SparkSession\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1c32942-e67d-4ca8-a966-ae89aa5146b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "71b94c7c-47c7-402a-bac2-502c3d01b095",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+----+-----------+---------+----+---------+----+-----+--------+-------------+--------+--------------------+----+------------------------+----------------------+-----------------+----------------------+-----------------+------------------+---------------------+--------------------------+---------------------+--------------------+--------------------+-----------------+\n| time|month|year|temperature|feelslike|wind|direction|gust|cloud|humidity|precipitation|pressure|             weather|Rain|temperature_after_3_hour|feelslike_after_3_hour|wind_after_3_hour|direction_after_3_hour|gust_after_3_hour|cloud_after_3_hour|humidity_after_3_hour|precipitation_after_3_hour|pressure_after_3_hour|weather_after_3_hour|               label|rain_after_3_hour|\n+-----+-----+----+-----------+---------+----+---------+----+-----+--------+-------------+--------+--------------------+----+------------------------+----------------------+-----------------+----------------------+-----------------+------------------+---------------------+--------------------------+---------------------+--------------------+--------------------+-----------------+\n|00:00|    1|2017|       24.0|     28.0| 8.0|      ENE|12.0|  4.0|    86.0|          0.0|  1012.0|               Clear|   0|                    23.0|                  27.0|              8.0|                    NE|             10.0|               4.0|                 88.0|                       0.0|               1011.0|               Clear|               Clear|                0|\n|03:00|    1|2017|       23.0|     27.0| 8.0|       NE|10.0|  4.0|    88.0|          0.0|  1011.0|               Clear|   0|                    23.0|                  26.0|              8.0|                   NNE|             11.0|               7.0|                 85.0|                       0.0|               1012.0|               Sunny|               Sunny|                0|\n|06:00|    1|2017|       23.0|     26.0| 8.0|      NNE|11.0|  7.0|    85.0|          0.0|  1012.0|               Sunny|   0|                    28.0|                  33.0|             11.0|                   NNE|             13.0|               6.0|                 64.0|                       0.0|               1012.0|               Sunny|               Sunny|                0|\n|09:00|    1|2017|       28.0|     33.0|11.0|      NNE|13.0|  6.0|    64.0|          0.0|  1012.0|               Sunny|   0|                    31.0|                  35.0|             10.0|                   ENE|             12.0|              62.0|                 53.0|                       0.0|               1010.0|       Partly cloudy|       Partly cloudy|                0|\n|12:00|    1|2017|       31.0|     35.0|10.0|      ENE|12.0| 62.0|    53.0|          0.0|  1010.0|       Partly cloudy|   0|                    31.0|                  36.0|              1.0|                   NNE|              1.0|              79.0|                 57.0|                       0.0|               1009.0|              Cloudy|              Cloudy|                0|\n|15:00|    1|2017|       31.0|     36.0| 1.0|      NNE| 1.0| 79.0|    57.0|          0.0|  1009.0|              Cloudy|   0|                    26.0|                  29.0|              5.0|                   ESE|             10.0|              40.0|                 77.0|                       0.0|               1010.0|       Partly cloudy|       Partly cloudy|                0|\n|18:00|    1|2017|       26.0|     29.0| 5.0|      ESE|10.0| 40.0|    77.0|          0.0|  1010.0|       Partly cloudy|   0|                    25.0|                  28.0|              8.0|                    NE|             15.0|              29.0|                 79.0|                       0.2|               1011.0|Patchy rain possible|Patchy rain possible|                0|\n|21:00|    1|2017|       25.0|     28.0| 8.0|       NE|15.0| 29.0|    79.0|          0.2|  1011.0|Patchy rain possible|   0|                    24.0|                  26.0|             10.0|                   NNE|             17.0|              12.0|                 84.0|                       0.0|               1011.0|               Clear|               Clear|                0|\n|00:00|    1|2017|       24.0|     26.0|10.0|      NNE|17.0| 12.0|    84.0|          0.0|  1011.0|               Clear|   0|                    23.0|                  26.0|              8.0|                    NE|             14.0|              17.0|                 85.0|                       0.0|               1010.0|               Clear|               Clear|                0|\n|03:00|    1|2017|       23.0|     26.0| 8.0|       NE|14.0| 17.0|    85.0|          0.0|  1010.0|               Clear|   0|                    24.0|                  26.0|             10.0|                    NE|             14.0|              16.0|                 80.0|                       0.0|               1011.0|               Clear|               Clear|                0|\n|06:00|    1|2017|       24.0|     26.0|10.0|       NE|14.0| 16.0|    80.0|          0.0|  1011.0|               Clear|   0|                    29.0|                  32.0|             12.0|                    NE|             14.0|               9.0|                 62.0|                       0.0|               1012.0|               Sunny|               Sunny|                0|\n|09:00|    1|2017|       29.0|     32.0|12.0|       NE|14.0|  9.0|    62.0|          0.0|  1012.0|               Sunny|   0|                    32.0|                  36.0|             12.0|                     E|             14.0|              55.0|                 53.0|                       0.0|               1010.0|       Partly cloudy|       Partly cloudy|                0|\n|12:00|    1|2017|       32.0|     36.0|12.0|        E|14.0| 55.0|    53.0|          0.0|  1010.0|       Partly cloudy|   0|                    31.0|                  36.0|              9.0|                     E|             13.0|              19.0|                 59.0|                       1.6|               1009.0|Patchy rain possible|Patchy rain possible|                0|\n|15:00|    1|2017|       31.0|     36.0| 9.0|        E|13.0| 19.0|    59.0|          1.6|  1009.0|Patchy rain possible|   0|                    26.0|                  30.0|              6.0|                   ESE|             12.0|              34.0|                 76.0|                       0.0|               1011.0|       Partly cloudy|       Partly cloudy|                0|\n|18:00|    1|2017|       26.0|     30.0| 6.0|      ESE|12.0| 34.0|    76.0|          0.0|  1011.0|       Partly cloudy|   0|                    25.0|                  28.0|              9.0|                   ENE|             17.0|              21.0|                 77.0|                       0.0|               1012.0|               Clear|               Clear|                0|\n|21:00|    1|2017|       25.0|     28.0| 9.0|      ENE|17.0| 21.0|    77.0|          0.0|  1012.0|               Clear|   0|                    24.0|                  27.0|              9.0|                    NE|             15.0|              32.0|                 84.0|                       0.0|               1011.0|       Partly cloudy|       Partly cloudy|                0|\n|00:00|    1|2017|       24.0|     27.0| 9.0|       NE|15.0| 32.0|    84.0|          0.0|  1011.0|       Partly cloudy|   0|                    23.0|                  26.0|              8.0|                    NE|             14.0|              38.0|                 85.0|                       0.0|               1010.0|       Partly cloudy|       Partly cloudy|                0|\n|03:00|    1|2017|       23.0|     26.0| 8.0|       NE|14.0| 38.0|    85.0|          0.0|  1010.0|       Partly cloudy|   0|                    23.0|                  26.0|              8.0|                    NE|             11.0|              20.0|                 83.0|                       0.0|               1011.0|               Sunny|               Sunny|                0|\n|06:00|    1|2017|       23.0|     26.0| 8.0|       NE|11.0| 20.0|    83.0|          0.0|  1011.0|               Sunny|   0|                    28.0|                  31.0|             10.0|                    NE|             12.0|              12.0|                 64.0|                       0.0|               1011.0|               Sunny|               Sunny|                0|\n|09:00|    1|2017|       28.0|     31.0|10.0|       NE|12.0| 12.0|    64.0|          0.0|  1011.0|               Sunny|   0|                    32.0|                  36.0|              9.0|                     E|             10.0|              18.0|                 49.0|                       0.0|               1009.0|               Sunny|               Sunny|                0|\n+-----+-----+----+-----------+---------+----+---------+----+-----+--------+-------------+--------+--------------------+----+------------------------+----------------------+-----------------+----------------------+-----------------+------------------+---------------------+--------------------------+---------------------+--------------------+--------------------+-----------------+\nonly showing top 20 rows\n\n"
     ]
    }
   ],
   "source": [
    "# Đường dẫn đến HDFS trên localhost:9000\n",
    "delta_table_path = \"dbfs:/minhhieu/delta/gold/weather_features\"\n",
    "\n",
    "\n",
    "# Đọc lại dữ liệu từ Delta Table\n",
    "df = spark.read.format(\"delta\").load(delta_table_path)\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "\n",
    "num_rows = df.count()\n",
    "\n",
    "df = df.limit(num_rows - 1)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef66081f-dd33-4a76-ba79-2d6a9a326524",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng cột: 26\nSố lượng dòng: 8510\n"
     ]
    }
   ],
   "source": [
    "# Đếm số lượng cột\n",
    "num_columns = len(df.columns)\n",
    "print(f\"Số lượng cột: {num_columns}\")\n",
    "\n",
    "# Đếm số lượng dòng\n",
    "num_rows = df.count()\n",
    "print(f\"Số lượng dòng: {num_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac234b5f-d2ab-47a3-ae46-04211ed4fab1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping Direction: {'ENE': 8, 'NE': 10, 'NNE': 9, 'ESE': 3, 'E': 5, 'SE': 0, 'SSE': 4, 'NNW': 14, 'WSW': 1, 'S': 11, 'WNW': 12, 'NW': 15, 'W': 7, 'SW': 2, 'SSW': 6, 'N': 13}\nMapping Weather: {'Clear': 1, 'Sunny': 2, 'Partly cloudy': 0, 'Cloudy': 5, 'Patchy rain possible': 3, 'Light rain shower': 6, 'Overcast': 7, 'Moderate or heavy rain shower': 4, 'Patchy light drizzle': 12, 'Torrential rain shower': 9, 'Light drizzle': 14, 'Patchy light rain': 10, 'Thundery outbreaks possible': 8, 'Light rain': 13, 'Patchy light rain with thunder': 11, 'Moderate rain': 17, 'Moderate rain at times': 16, 'Mist': 15, 'Heavy rain at times': 19, 'Heavy rain': 18}\nMapping Direction After 3 Hours: {'NE': 10, 'NNE': 9, 'ENE': 8, 'ESE': 3, 'E': 5, 'SE': 0, 'SSE': 4, 'NNW': 14, 'WSW': 1, 'S': 11, 'WNW': 12, 'NW': 15, 'W': 7, 'SW': 2, 'SSW': 6, 'N': 13}\nMapping Weather After 3 Hours: {'Clear': 1, 'Sunny': 2, 'Partly cloudy': 0, 'Cloudy': 5, 'Patchy rain possible': 3, 'Light rain shower': 6, 'Overcast': 7, 'Moderate or heavy rain shower': 4, 'Patchy light drizzle': 12, 'Torrential rain shower': 9, 'Light drizzle': 14, 'Patchy light rain': 10, 'Thundery outbreaks possible': 8, 'Light rain': 13, 'Patchy light rain with thunder': 11, 'Moderate rain': 17, 'Moderate rain at times': 16, 'Mist': 15, 'Heavy rain at times': 19, 'Heavy rain': 18}\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Tạo bộ chuyển đổi cho các cột\n",
    "indexers = [\n",
    "    StringIndexer(inputCol=\"direction\", outputCol=\"direction_index\"),\n",
    "    StringIndexer(inputCol=\"weather\", outputCol=\"weather_index\"),\n",
    "    StringIndexer(inputCol=\"direction_after_3_hour\", outputCol=\"direction_after_index\"),\n",
    "    StringIndexer(inputCol=\"weather_after_3_hour\", outputCol=\"weather_after_index\"),\n",
    "]\n",
    "\n",
    "# Áp dụng pipeline để chuyển đổi tất cả các cột cùng lúc\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "df = pipeline.fit(df).transform(df)\n",
    "\n",
    "# Trích xuất ánh xạ thành dictionary\n",
    "direction_mapping = df.select(\"direction\", \"direction_index\").distinct().collect()\n",
    "weather_mapping = df.select(\"weather\", \"weather_index\").distinct().collect()\n",
    "direction_after_mapping = df.select(\"direction_after_3_hour\", \"direction_after_index\").distinct().collect()\n",
    "weather_after_mapping = df.select(\"weather_after_3_hour\", \"weather_after_index\").distinct().collect()\n",
    "\n",
    "# Lưu vào dictionary\n",
    "direction_dict = {row[\"direction\"]: int(row[\"direction_index\"]) for row in direction_mapping}\n",
    "weather_dict = {row[\"weather\"]: int(row[\"weather_index\"]) for row in weather_mapping}\n",
    "direction_after_dict = {row[\"direction_after_3_hour\"]: int(row[\"direction_after_index\"]) for row in direction_after_mapping}\n",
    "weather_after_dict = {row[\"weather_after_3_hour\"]: int(row[\"weather_after_index\"]) for row in weather_after_mapping}\n",
    "\n",
    "# In kết quả\n",
    "print(\"Mapping Direction:\", direction_dict)\n",
    "print(\"Mapping Weather:\", weather_dict)\n",
    "print(\"Mapping Direction After 3 Hours:\", direction_after_dict)\n",
    "print(\"Mapping Weather After 3 Hours:\", weather_after_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd0c6bf5-1106-4cb1-b2ae-0d54da34d290",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Thay thế cột chuỗi bằng cột đã mã hóa\n",
    "df = df \\\n",
    "    .drop(\"direction\", \"weather\", \"direction_after_3_hour\", \"weather_after_3_hour\") \\\n",
    "    .withColumnRenamed(\"direction_index\", \"direction\") \\\n",
    "    .withColumnRenamed(\"weather_index\", \"weather\") \\\n",
    "    .withColumnRenamed(\"direction_after_index\", \"direction_after_3_hour\") \\\n",
    "    .withColumnRenamed(\"weather_after_index\", \"weather_after_3_hour\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "412008ce-a2b1-44ea-a316-b9781e5d4eb5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "\n",
    "# Sửa cột 'time', loại bỏ ':00'\n",
    "df = df.withColumn(\"time\", regexp_replace(\"time\", \":00\", \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99d0746a-6852-4a09-b581-4a9ce9840917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def cast_columns_to_float(df: DataFrame, columns: list) -> DataFrame:\n",
    "    for c in columns:\n",
    "        df = df.withColumn(c, col(c).cast(\"float\"))\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dc4059eb-ff25-41f1-b280-0b1d21e4ca66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sin, cos, col\n",
    "import math\n",
    "\n",
    "# Chuyển đổi cột 'time' (giờ trong ngày) thành sin/cos\n",
    "df = df.withColumn(\"time_sin\", sin(2 * math.pi * col(\"time\") / 24))\n",
    "df = df.withColumn(\"time_cos\", cos(2 * math.pi * col(\"time\") / 24))\n",
    "\n",
    "# Chuyển đổi cột 'month' (tháng trong năm) thành sin/cos\n",
    "df = df.withColumn(\"month_sin\", sin(2 * math.pi * col(\"month\") / 12))\n",
    "df = df.withColumn(\"month_cos\", cos(2 * math.pi * col(\"month\") / 12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7833ce2f-344d-40f7-9188-d17d18f84222",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "input_cols = [\n",
    "    'time', 'month', 'temperature', 'feelslike', 'wind',\n",
    "    'direction', 'gust', 'cloud', 'humidity', 'precipitation',\n",
    "    'pressure',\n",
    "    'time_sin', 'time_cos',  # Biểu diễn thời gian trong ngày\n",
    "    'month_sin', 'month_cos'  # Biểu diễn tháng trong năm\n",
    "]\n",
    "\n",
    "output_cols = [\n",
    "    'temperature_after_3_hour',\n",
    "    'feelslike_after_3_hour',\n",
    "    'wind_after_3_hour',\n",
    "    'direction_after_3_hour',\n",
    "    'gust_after_3_hour',\n",
    "    'cloud_after_3_hour',\n",
    "    'humidity_after_3_hour',\n",
    "    'precipitation_after_3_hour',\n",
    "    'pressure_after_3_hour'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d28b6688-678f-4651-80ed-5767143002ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = cast_columns_to_float(df, input_cols + output_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13ff4974-4441-4745-af36-1a210d7b3581",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- time: float (nullable = true)\n |-- month: float (nullable = true)\n |-- year: string (nullable = true)\n |-- temperature: float (nullable = true)\n |-- feelslike: float (nullable = true)\n |-- wind: float (nullable = true)\n |-- gust: float (nullable = true)\n |-- cloud: float (nullable = true)\n |-- humidity: float (nullable = true)\n |-- precipitation: float (nullable = true)\n |-- pressure: float (nullable = true)\n |-- Rain: integer (nullable = true)\n |-- temperature_after_3_hour: float (nullable = true)\n |-- feelslike_after_3_hour: float (nullable = true)\n |-- wind_after_3_hour: float (nullable = true)\n |-- gust_after_3_hour: float (nullable = true)\n |-- cloud_after_3_hour: float (nullable = true)\n |-- humidity_after_3_hour: float (nullable = true)\n |-- precipitation_after_3_hour: float (nullable = true)\n |-- pressure_after_3_hour: float (nullable = true)\n |-- label: string (nullable = true)\n |-- rain_after_3_hour: integer (nullable = true)\n |-- direction: float (nullable = false)\n |-- weather: double (nullable = false)\n |-- direction_after_3_hour: float (nullable = false)\n |-- weather_after_3_hour: double (nullable = false)\n |-- time_sin: float (nullable = true)\n |-- time_cos: float (nullable = true)\n |-- month_sin: float (nullable = true)\n |-- month_cos: float (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "92c885bf-4b8f-4279-b9d0-9af9d7922d81",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=input_cols, outputCol=\"features\")\n",
    "df = assembler.transform(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1188f08f-a900-4021-b6b3-b3847a4c8ae0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Đang huấn luyện mô hình cho: temperature_after_3_hour\n✅ RMSE cho temperature_after_3_hour: 1.877\n🎯 Đang huấn luyện mô hình cho: feelslike_after_3_hour\n✅ RMSE cho feelslike_after_3_hour: 1.613\n🎯 Đang huấn luyện mô hình cho: wind_after_3_hour\n✅ RMSE cho wind_after_3_hour: 2.428\n🎯 Đang huấn luyện mô hình cho: direction_after_3_hour\n✅ RMSE cho direction_after_3_hour: 3.391\n🎯 Đang huấn luyện mô hình cho: gust_after_3_hour\n✅ RMSE cho gust_after_3_hour: 4.306\n🎯 Đang huấn luyện mô hình cho: cloud_after_3_hour\n✅ RMSE cho cloud_after_3_hour: 22.324\n🎯 Đang huấn luyện mô hình cho: humidity_after_3_hour\n✅ RMSE cho humidity_after_3_hour: 4.184\n🎯 Đang huấn luyện mô hình cho: precipitation_after_3_hour\n✅ RMSE cho precipitation_after_3_hour: 1.972\n🎯 Đang huấn luyện mô hình cho: pressure_after_3_hour\n✅ RMSE cho pressure_after_3_hour: 0.904\n"
     ]
    }
   ],
   "source": [
    "# Thư viện cần thiết\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number, col\n",
    "\n",
    "# Lặp qua từng cột đầu ra (output cần dự đoán) – ngoại trừ 'weather_after_3_hour' vì đây là phân loại\n",
    "for target in output_cols:  # Bỏ weather_after_3_hour (classification)\n",
    "    # Loại bỏ các dòng chứa giá trị null trong cột đặc trưng (input) và nhãn mục tiêu (target)\n",
    "    current_df = df.dropna(subset=input_cols + [target])\n",
    "\n",
    "    # Nếu sau khi lọc không còn dòng nào → bỏ qua mô hình này\n",
    "    if current_df.count() == 0:\n",
    "        print(f\"⚠️ Bỏ qua {target} vì không còn dòng sau khi dropna.\")\n",
    "        continue\n",
    "\n",
    "    print(f\"🎯 Đang huấn luyện mô hình cho: {target}\")\n",
    "\n",
    "    # Tạo cột số thứ tự dòng để chia dữ liệu theo thời gian (giả lập thời gian bằng thứ tự)\n",
    "    window = Window.orderBy(monotonically_increasing_id())\n",
    "    indexed_df = current_df.withColumn(\"row_num\", row_number().over(window))\n",
    "\n",
    "    # Chia tập train/test theo thứ tự dòng (80% huấn luyện, 20% kiểm thử)\n",
    "    total_rows = indexed_df.count()\n",
    "    split_point = int(total_rows * 0.8)\n",
    "\n",
    "    train_data = indexed_df.filter(col(\"row_num\") <= split_point).drop(\"row_num\")\n",
    "    test_data = indexed_df.filter(col(\"row_num\") > split_point).drop(\"row_num\")\n",
    "\n",
    "    # Khởi tạo và huấn luyện mô hình Random Forest hồi quy\n",
    "    model = RandomForestRegressor(\n",
    "        featuresCol=\"features\",  # Cột đặc trưng đầu vào\n",
    "        labelCol=target,         # Cột đầu ra cần dự đoán\n",
    "        numTrees=100             # Số cây trong rừng\n",
    "    )\n",
    "    model_fitted = model.fit(train_data)\n",
    "\n",
    "    # Dự đoán trên tập kiểm thử và đánh giá bằng chỉ số RMSE\n",
    "    predictions = model_fitted.transform(test_data)\n",
    "    evaluator = RegressionEvaluator(\n",
    "        labelCol=target,\n",
    "        predictionCol=\"prediction\",\n",
    "        metricName=\"rmse\"       # Root Mean Squared Error\n",
    "    )\n",
    "    rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "    print(f\"✅ RMSE cho {target}: {rmse:.3f}\")\n",
    "\n",
    "    # Lưu mô hình đã huấn luyện vào thư mục trên DBFS (Databricks File System)\n",
    "    model_fitted.write().overwrite().save(f\"dbfs:/minhhieu/delta/models/{target}_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b1e233f-54e2-4f92-9cc5-878c021ec0c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy for weather_after_3_hour: 0.583\n✅ F1-score for weather_after_3_hour: 0.535\n"
     ]
    }
   ],
   "source": [
    "# Thư viện cần thiết từ PySpark ML\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Chia dữ liệu thành tập huấn luyện và kiểm thử (80% train, 20% test)\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Khởi tạo mô hình Random Forest Classifier\n",
    "clf = RandomForestClassifier(\n",
    "    featuresCol=\"features\",                    # Cột chứa vector đặc trưng\n",
    "    labelCol=\"weather_after_3_hour\",           # Cột nhãn phân loại đầu ra\n",
    "    numTrees=200,                              # Số cây trong rừng\n",
    "    maxDepth=10                                # Độ sâu tối đa của mỗi cây\n",
    ")\n",
    "\n",
    "# Huấn luyện mô hình với tập train\n",
    "model = clf.fit(train_data)\n",
    "\n",
    "# Dự đoán trên tập test\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Khởi tạo bộ đánh giá Accuracy và F1-score\n",
    "acc_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"weather_after_3_hour\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\"                     # Tính độ chính xác\n",
    ")\n",
    "\n",
    "f1_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"weather_after_3_hour\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"f1\"                           # Tính chỉ số F1 (harmonic mean giữa precision & recall)\n",
    ")\n",
    "\n",
    "# Tính toán độ chính xác và F1-score trên tập kiểm thử\n",
    "accuracy = acc_evaluator.evaluate(predictions)\n",
    "f1_score = f1_evaluator.evaluate(predictions)\n",
    "\n",
    "# In kết quả ra màn hình\n",
    "print(f\"✅ Accuracy for weather_after_3_hour: {accuracy:.3f}\")\n",
    "print(f\"✅ F1-score for weather_after_3_hour: {f1_score:.3f}\")\n",
    "\n",
    "# Lưu mô hình đã huấn luyện vào hệ thống tệp (DBFS – Databricks File System)\n",
    "model.write().overwrite().save(\"dbfs:/minhhieu/delta/models/weather_classifier_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16555183-2551-46f9-b735-390e08b13375",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n|weather_after_3_hour|\n+--------------------+\n|                 1.0|\n|                 2.0|\n|                 0.0|\n|                 5.0|\n|                 3.0|\n|                 6.0|\n|                 7.0|\n|                 4.0|\n|                12.0|\n|                 9.0|\n|                14.0|\n|                10.0|\n|                 8.0|\n|                13.0|\n|                11.0|\n|                17.0|\n|                16.0|\n|                15.0|\n|                19.0|\n|                18.0|\n+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select(\"weather_after_3_hour\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "91499a03-8ac8-46d6-939b-c163d905e38b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# Gán nhãn: các loại thời tiết liên quan đến mưa → 1, còn lại → 0\n",
    "rain_labels = [3, 4, 6, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19]  # các giá trị mapping tương ứng với mưa\n",
    "\n",
    "df = df.withColumn(\"label_after_3_hour\", when(col(\"weather_after_3_hour\").isin(rain_labels), 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "12d0f1b0-dc04-4797-af97-27e71b8cb037",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy for weather_after_3_hour: 0.876\n✅ F1-score for weather_after_3_hour: 0.870\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Train-test split\n",
    "train_data, test_data = df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# RandomForestClassifier\n",
    "clf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"label_after_3_hour\", numTrees=200, maxDepth=10)\n",
    "\n",
    "model = clf.fit(train_data)\n",
    "\n",
    "# Dự đoán\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Đánh giá\n",
    "acc_evaluator = MulticlassClassificationEvaluator(labelCol=\"label_after_3_hour\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "f1_evaluator = MulticlassClassificationEvaluator(labelCol=\"label_after_3_hour\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "\n",
    "accuracy = acc_evaluator.evaluate(predictions)\n",
    "f1_score = f1_evaluator.evaluate(predictions)\n",
    "\n",
    "print(f\"✅ Accuracy for weather_after_3_hour: {accuracy:.3f}\")\n",
    "print(f\"✅ F1-score for weather_after_3_hour: {f1_score:.3f}\")\n",
    "\n",
    "model.write().overwrite().save(\"dbfs:/minhhieu/delta/models/weather_classifier_model_2\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "train",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}